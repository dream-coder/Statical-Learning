**Non- Linear Modelling**

```{r}
library(ISLR)
attach(Wage)
```

**Polynomial Regression**
```{r}
poly.fit = lm(wage~poly(age,4), data=Wage)
coef(summary(poly.fit))
```
Above we are using orthogonal polynomials, which means that each column is linear combination of variables age, age^2, age^3, age^4.

we can use also use raw polynomials by:
```{r}
poly.fit2 = lm(wage~poly(age,4,raw=T), data= Wage)
coef(summary(poly.fit2))
```
choice of type of polynomial does not affect fitted values obtained but it affects coefficient estimate as seen.

we can fit polynomial regression by:

```{r}
poly.fit3 = lm(wage~age+I(age^2)+I(age^3)+I(age^4), data=Wage)
coef(poly.fit3)
```

we will now create grid of values of `age` for which we want predictions.

```{r}
age.grid = seq(from=range(age)[1], to=range(age)[2])
```
above function will generate grid of 63 age variables from 18 to 80.

```{r}
preds = predict(poly.fit,newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit+2*preds$se.fit,preds$fit-2*preds$se.fit)

```

```{r}

par(mfrow=c(1,2),mar=c(4.5,4.5,1,1), oma=c(0,0,4,0))
```
![Plot Margin](https://www.r-graph-gallery.com/74-margin-and-oma-cheatsheet_files/figure-html/thecode-1.png)


As we can see there are 2 margins. `mar` argument is used to set margins and `oma` to set outer margins.


```{r}
plot(age,wage,xlim=range(age),cex=0.5, col="darkgrey")
title("Degree- 4 Polynomial", outer=T)
lines(age.grid,preds$fit,lwd=2, col="blue")
matlines(age.grid,se.bands, lwd=1, col="blue",lty=3)
```

```{r}

preds2 = predict(poly.fit2, newdata=list(age=age.grid), se=TRUE)
max(abs(preds$fit-preds2$fit))

```
Above quantity suggests that there is very minimal changes is prediction between orthogonal and raw polynomials.


For determing degree of polynomial, we can use hypothesis tests.

We will now fit model ranging from linear to a 5 degree polynomial and will determine the simplest model explaining the relationship between wage and age. 

We will use the `anova()` function which performs analysis of variance (ANOVA using an F-test) in order to test null hypothesis that a model M~1~ is sufficient to explain the data against the alternative hypothesis that a more complex model M~2~ is required.

In order to use `anova()` function, M~1~ and M~2~ must be nested models i.e. all of predictors in M~1~ must be a subset of predictors in M~2~.

```{r}
fit.1 = lm(wage~age, data=Wage)
fit.2 = lm(wage~poly(age,2), data=Wage)
fit.3 = lm(wage~poly(age,3), data=Wage)
fit.4 = lm(wage~poly(age,4), data=Wage)
fit.5 = lm(wage~poly(age,5), data=Wage)
```

using `anova()` function:

```{r}
anova(fit.1,fit.2,fit.3,fit.4,fit.5)
```
P- value comparing linear *model 1* to quadaratic *model 2* is essentialy zero, indicating that a linear fit is not sufficient.
Similarly, P- value comparing quadratic *model 2* to cubic *model 3* is very low(0.0016), so quadratic fit is also insufficient.
The p-value comparing the cubic and degree-4 polynomials, *model 3* and *model 4*, is approximately 5% while the degree-5 polynomial *model 5* seems unnecessary because its p-value is 0.37. Hence, either a cubic or a quartic polynomial appear to provide a reasonable ???t to the data.

we can also obtain P- values briefly by using fact that `poly()` creates orthogonal polynomials.

```{r}
coef(summary(fit.5))
```

We can also use `anova()` method with or without polynomial, it also works when we have other terms in model

```{r}
fit.1 = lm(wage~education+age, data= Wage)
fit.2 = lm(wage~education+poly(age,2), data= Wage)
fit.3 = lm(wage~education+poly(age,3), data= Wage)
anova(fit.1,fit.2,fit.3)
```

We can also choose polynomial using degree validation.

We will now predict whether an individual ears more than $250,000 per year.
```{r}
fit = glm(I(wage>250)~poly(age,4), data= Wage, family = binomial)
```
we use wrapper `I()` to create binary response. 

```{r}
preds = predict(fit, newdata=list(age=age.grid), se=TRUE)
```

to calculate confidence interval:

```{r}
pfit = exp(preds$fit)/(1+exp(preds$fit))
se.bands.logit = cbind(preds$fit+2*preds$se.fit, preds$fit-2*preds$se.fit)
se.bands = exp(se.bands.logit)/(1 + exp(se.bands.logit))
```


