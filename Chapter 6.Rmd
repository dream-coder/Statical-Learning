#Linear Model selection


```{r}
library(ISLR)
summary(Hitters)
sum(is.na(Hitters))
```

We can see that there are some miisng values here so we will remove here.

```{r}
Hitters  = na.omit(Hitters)
sum(is.na(Hitters$Salary))
```
##Best Subset Regression:
Best subset selection is performed using regsubsets() function which is part of leaps library.

```{r}
library(leaps)
regfit.full = regsubsets(Salary~., data=Hitters)
summary(regfit.full)
```
This output indicates that best two variable model contains only Hits and CRBI.

By default, regsubsets() function give best subsets up to size 8 but we can increase it.

```{r}
regfit.full = regsubsets(Salary~., data= Hitters, nvmax = 19)
reg.summary = summary(regfit.full)
names(reg.summary)
```
We can get R^2^, RSS, adjusted R^2^, C~p~, bic. we can examine this to select best overall model.
we can now plot errors to identify best model.

```{r}
plot(reg.summary$cp, xlab="No. of variables", ylab="Cp")
```

we can see that model with 10 variables has lowest Cp.

 we can also use-
```{r}
which.min(reg.summary$cp)
plot(reg.summary$cp, xlab="No. of variables", ylab="Cp")
points(10,reg.summary$cp[10], pch=20, col="red")
```

The regsubsets() has a inbuilt plot method, which can be used.

```{r}
plot(regfit.full, scale="Cp")
```

For this plot we can see that for each value of Cp on y-axis:
black corresponds to variables that are in and white that are out.

we can get coefficients by:
```{r}
coef(regfit.full,10)
```


##Forward Stepwise Selection
Here we also use regsubsets() function but with method="forward" as additional argument.

```{r}
regfit.fwd = regsubsets(Salary~., data= Hitters, nvmax=19, method="forward")
summary(regfit.fwd)
plot(regfit.fwd, scale="Cp")
```



##Model Selection Using Validation Set:

we must use only the training observations to perform all aspects of model-???tting-including variable selection. Therefore, the determination of which model of a given size is best must be made using only the training observations.


```{r}
dim(Hitters)
set.seed(1)
```

```{r}
train = sample(1:263,180, replace=FALSE)
train
```

```{r}
regfit.fwd = regsubsets(Salary~., data=Hitters[train,], method="forward", nvmax=19)
```

Now we will make predictions for data not used in training There is no predict() method for regsubsets.as we have 19 models we will setup a vector of length 19.

```{r}
val.errors = rep(NA,19)
x.test = model.matrix(Salary~., data=Hitters[-train,])
for(i in 1:19){
  coefi = coef(regfit.fwd, id=i)
  pred = x.test[,names(coefi)]%*%coefi
  val.errors[i] = mean((Hitters$Salary[-train]-pred)^2)
}
```
by[,names(coefi)] in above code we are getting a subset of columns of x.test vector that are part of our coefi vector.
%*% is doing matrix multiplication with values of coefficients.


we can now plot Root MSE errors.
 
```{r}
plot(sqrt(val.errors), ylab= "Root MSE",ylim = c(300,420), pch=19, type="b")
```

We also put RSS model on same plot. we removed 1st element of regfit.fwd as 1 element correspond to null model which we have not included in validation errors.
```{r}
plot(sqrt(val.errors), ylab= "Root MSE",ylim = c(200,420), pch=19, type="b")
points(sqrt(regfit.fwd$rss[-1]/180), col="blue", pch=19, type="b" )
legend("topright", legend=c("training","validation"), col=c("blue", "black"), pch=19)
```
RSS decreases monotonically.

we can also write our own function for getting prediction from regsubsets model.

```{r}
predict.regsubsets = function(object, newdata, id,...){
  form = as.formula(object$call[[2]])
  mat = model.matrix(form, newdata)
  coefi = coef(object,id=id)
  mat[,names(coefi)]%*%coefi
}
```

##Model Selection by Cross Validation-
we will do 10-fold cross validation.
```{r}
set.seed(11)
folds = sample(rep(1:10,length=nrow(Hitters)))
folds
table(folds)
```

we will create an matrix to store cross validation errors.this matrix will have 10 rows and 19 columns
```{r}
cv.errors = matrix(NA,10,19)
```

```{r}
for(k in 1:10){
  best.fit = regsubsets(Salary~., data=Hitters[folds!=k,],nvmax=19, method="forward" )
  for (i in 1:19){
    pred = predict(best.fit, Hitters[folds==k,], id=i)
    cv.errors[k,i] = mean((Hitters$Salary[folds==k]-pred)^2)
  }
  
  }
```


we will use apply() function to average over columns of matrix in order to obtain a vector for which kth element is cross validation error for k-variable model.

```{r}
rmse.cv = sqrt(apply(cv.errors,2,mean))
rmse.cv
```
we can make a plot of that.
```{r}
plot(rmse.cv,pch=19 ,type="b")
```

##Ridge Regression


we will use package glmnet package to perform ridge regression and lasso. This package does not use model formula language, so we will set up an 'x' and 'y'.

```{r}
x = model.matrix(Salary~., data=Hitters)[,-1]
y= Hitters$Salary
```

glmnet() function has an alpha argument to tell which model to fit. 
alpha=0 for ridge regression model
alpha=1 for lasso model.
By default glmnet() function standardizes the variables.

```{r}
library(glmnet)
fit.ridge = glmnet(x,y, alpha=0)
plot(fit.ridge,xvar="lambda", label=TRUE)

```
There is also a cv.glmnet function that will do cross validation
```{r}
cv.ridge = cv.glmnet(x,y,alpha=0)#default k =10
plot(cv.ridge)
```
1st verical line from left indicates minimum error.
2nd werical line from left indicates 1 standard error away from minimum.

##LASSO

Now we will use lasso regression model, alpha=1

```{r}
fit.lasso = glmnet(x,y)
plot(fit.lasso, xvar="lambda", label=TRUE)
```
```{r}
plot(fit.lasso, xvar="dev", label=TRUE)
```

```{r}
cv.lasso = cv.glmnet(x,y, alpha=1)
plot(cv.lasso)
```

```{r}
coef(cv.lasso)
```


we can also use validation set approach to select `lambda` for lasso/ridge.

```{r}
lasso.tr = glmnet(x[train,],y[train], alpha=1)
lasso.tr
pred = predict(lasso.tr, x[-train,])
dim(pred)
mean((y[-train]-pred)^2)
```



```{r}
rmse = sqrt(apply((y[-train]-pred)^2,2,mean))
plot(log(lasso.tr$lambda),rmse,type="b", xlab="Log(lambda)")

```
we can extract best lambda by:
```{r}
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s=lam.best)
```


##PCR and PLS regression

###Principal Components Regression
```{r}
library(pls)
set.seed(2)
pcr.fit = pcr(Salary~., data=Hitters, scale=TRUE, validation="CV")
```
syntax of pcr() function is similar to that of lm(); setting scale=TRUE standardize each variable.
setting validation="CV" causes pcr() to compute ten-fold cross validation error for each possible value of number of principal components used.
```{r}
summary(pcr.fit)
```

comps correspond to no. of principal componenets used. 

`pcr()` reports the root mean squared error.To get usual MSE we need to square the error.

We can also plot the cross validation scores using the `validationplot()` function. using argument `val.type="MSEP"` will plot cross validation MSE.

```{r}
validationplot(pcr.fit,val.type="MSEP")
```
`summary()` also provides percentage of variance explained in predictors and reponse explained by different number of components.
setting M = 1 only captures 38.31% of all the variance, or information, in the predictors. In contrast, using M = 6 increases the value to 88.63%. If we were to use all M = p = 19 components, this would increase to 100%. 

performing PCR on training data.
```{r}
set.seed(1)
pcr.fit = pcr(Salary~., data=Hitters, subset=train, scale=TRUE, validation="CV")
validationplot(pcr.fit, val.type="MSEP")
```
finding test MSE when M=7 components are used.

```{r}
pcr.pred = predict(pcr.fit,Hitters[-train,], ncomp=7)
mean((pcr.pred-Hitters$Salary[-train])^2)
```
```{r}
pcr.fit1 = pcr(y~x, scale=TRUE, ncomp=7)
summary(pcr.fit1)
```

###Partial Least Squares

we can perform partial least squares regression using the `plsr()` function, part of pls library.

```{r}
set.seed(1)
pls.fit = plsr(Salary~., data=Hitters, subset=train, scale=TRUE, validation="CV")
summary(pls.fit)
```
lowest cross validation error occurs when M=3 partial least squares direction are used.

```{r}
pls.pred = predict(pls.fit,x[-train,], ncomp=3)
mean((pls.pred-y[-train])^2)
```
we can also perform PLS using full data set, using M=2.

```{r}
pls.fit1 = plsr(Salary~., data=Hitters, scale=TRUE, ncomp=3)
summary(pls.fit1)
```
Notice that the percentage of variance in Salary that the two-component PLS ???t explains, 46.40%, is almost as much as that explained using the ???nal seven-component model PCR ???t, 46.69%. This is because PCR only attempts to maximize the amount of variance explained in the predictors, while PLS searches for directions that explain variance in both the predictors and the response.
